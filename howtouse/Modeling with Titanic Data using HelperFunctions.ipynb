{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tests/titanic\\gender_submission.csv\n",
      "../tests/titanic\\test.csv\n",
      "../tests/titanic\\train.csv\n",
      "{'gender_submission.csv': '../tests/titanic\\\\gender_submission.csv', 'test.csv': '../tests/titanic\\\\test.csv', 'train.csv': '../tests/titanic\\\\train.csv'}\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import plotly\n",
    "import plotly.offline as pyoff\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "init_notebook_mode(connected = True)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "file_paths_dict = {}\n",
    "for dirname, _, filenames in os.walk('../tests/titanic'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        file_paths_dict[filename] =os.path.join(dirname, filename)\n",
    "\n",
    "print(file_paths_dict)\n",
    "# Any results you write to the current directory are saved as output.\n",
    "def load_data(path_to_file):\n",
    "    \"\"\"Function to load a csv file\"\"\"\n",
    "    return pd.read_csv(path_to_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the helper functions, go to my github repo https://github.com/SCK22/HelperFunctions/blob/development/ML \n",
    "use the HelperFunctionsMLClass.py \n",
    "I have copied everything from there and pasted here. Will build a package soon.\n",
    "Note: This repo is under active development.\n",
    "Feedback appreciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.HelperFunctionsMLClass import HelperFunctionsML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(file_paths_dict[\"train.csv\"])\n",
    "test = load_data(file_paths_dict[\"test.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = HelperFunctionsML(train)\n",
    "test = HelperFunctionsML(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12, 418, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nrows, train.ncols, test.nrows, test.ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succesfully set target column!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.set_target(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set_target': {'attributes': {'col_name': 'Survived'},\n",
       "  'needed_for_test': False}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.actions_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.check_has_na_values(), test.check_has_na_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train.get_cat_cols()\n",
    "num_cols = train.get_num_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols : ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "train.set_imputer_numeric()\n",
    "train.train_imputer_numeric()\n",
    "train.impute_numeric_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols : ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "test.dataset.loc[:,num_cols] = train.impute_numeric_cols(test_dataset=test.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols : ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "train.set_imputer_categorical()\n",
    "train.train_imputer_categorical()\n",
    "train.impute_categorical_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Null values in the dataset.\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.check_has_na_values(), test.check_has_na_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.create_dummy_data_frame([\"Sex\", \"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set_target': {'attributes': {'col_name': 'Survived'},\n",
       "  'needed_for_test': False},\n",
       " 'check_has_na_values': {'attributes': {}, 'needed_for_test': False},\n",
       " 'cat_num_extract': {'attributes': {}, 'needed_for_test': False},\n",
       " 'set_imputer_numeric': {'attributes': {'strategy': 'median'}},\n",
       " 'train_imputer_numeric': {'attributes': {}, 'needed_for_test': False},\n",
       " 'impute_numeric_cols': {'attributes': {}, 'needed_for_test': True},\n",
       " 'imputer_categorical': {'attributes': {'strategy': 'most_frequent'}},\n",
       " 'train_imputer_categorical': {'attributes': {}, 'needed_for_test': False},\n",
       " 'impute_categorical_cols': {'attributes': {}, 'needed_for_test': True},\n",
       " 'create_dummy_data_frame': {'attributes': {'columns_present': ['Sex_female',\n",
       "    'Sex_male',\n",
       "    'Embarked_C',\n",
       "    'Embarked_Q',\n",
       "    'Embarked_S']},\n",
       "  'needed_for_test': True}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.actions_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train.create_train_test_split(return_frames=True)\n",
    "train.create_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              train  validation           model_obj\n",
      "precision       NaN         NaN  LogisticRegression\n",
      "f1_score   0.721088    0.739336  LogisticRegression\n",
      "recall     0.779105    0.781288  LogisticRegression\n",
      "accuracy   0.802568    0.794776  LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\github\\helperfunctions\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "e:\\github\\helperfunctions\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_performance = train.apply_model_predict_validate(model_obj = log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'precision': None, 'f1_score': 0.7210884353741497, 'recall': 0.779104823747681, 'accuracy': 0.8025682182985554}, 'validation': {'precision': None, 'f1_score': 0.7393364928909952, 'recall': 0.7812876570838354, 'accuracy': 0.7947761194029851}, 'model_obj': 'LogisticRegression'}\n"
     ]
    }
   ],
   "source": [
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           train  validation               model_obj\n",
      "precision    NaN         NaN  DecisionTreeClassifier\n",
      "f1_score     1.0    0.719298  DecisionTreeClassifier\n",
      "recall       1.0    0.757904  DecisionTreeClassifier\n",
      "accuracy     1.0    0.761194  DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "model_performance = train.apply_model_predict_validate(model_obj = dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              train  validation               model_obj\n",
      "precision       NaN         NaN  DecisionTreeClassifier\n",
      "f1_score   0.759725    0.753623  DecisionTreeClassifier\n",
      "recall     0.808287    0.794027  DecisionTreeClassifier\n",
      "accuracy   0.831461    0.809701  DecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "dtree_max_depth = DecisionTreeClassifier(max_depth = 3)\n",
    "model_performance = train.apply_model_predict_validate(model_obj = dtree_max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support for using the models on test data coming soon. Stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_test_data():\n",
    "    test_num_df = pd.DataFrame(imputer.transform(test.loc[:,num_cols]))\n",
    "    test_num_df.columns = num_cols\n",
    "    test_cat_df = pd.get_dummies(test.loc[:,cat_cols])\n",
    "    test_cat_df = test_cat_df.loc[:,cat_df_cols]\n",
    "    test_data = pd.concat([test_num_df, test_cat_df],axis =1)\n",
    "    return test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
